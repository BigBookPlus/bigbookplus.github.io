<!doctype html><html lang=en><head><title>PyTorch中的lr_scheduler的用法</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.6a5cdf7499f781bae02ed80dbc345e1b18e8cf6108d1808a7d1fbbf08e5c006e.css integrity="sha256-alzfdJn3gbrgLtgNvDReGxjoz2EI0YCKfR+78I5cAG4="><link rel=icon type=image/png href=/images/favicon_hu_a23dc4244bee30eb.png><meta property="og:url" content="https://bigbookplus.github.io/posts/blogs/2021-08-24-pytorch-lr_scheduler/"><meta property="og:title" content="PyTorch中的lr_scheduler的用法"><meta property="og:description" content="几种常见的LR_Scheduler:
StepLR MultiStepLR ExponentialLR 对于一个基本的训练流程，LR_Scheduler可能不是必须的。但是对于一个完整的训练流程，LR_Scheduler就是必须存在的。LR_Scheduler跟在Optimizer之后，利用对Optim变量的跟踪，在Optim执行Update后，检查lr是否满足预设条件并对学习率learning_rate进行更新。
以StepLR为例，StepLR每隔N个epoch改变lr学习率为lr=lr*gamma。
import torch.optim.lr_scheduler as lr_scheduler optimizer = SGD(model, 0.1) scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) for epoch in range(20): for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() scheduler.step()"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta name=twitter:card content="summary"><meta name=twitter:title content="PyTorch中的lr_scheduler的用法"><meta name=twitter:description content="几种常见的LR_Scheduler:
StepLR MultiStepLR ExponentialLR 对于一个基本的训练流程，LR_Scheduler可能不是必须的。但是对于一个完整的训练流程，LR_Scheduler就是必须存在的。LR_Scheduler跟在Optimizer之后，利用对Optim变量的跟踪，在Optim执行Update后，检查lr是否满足预设条件并对学习率learning_rate进行更新。
以StepLR为例，StepLR每隔N个epoch改变lr学习率为lr=lr*gamma。
import torch.optim.lr_scheduler as lr_scheduler optimizer = SGD(model, 0.1) scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) for epoch in range(20): for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() scheduler.step()"><meta name=description content="PyTorch中的lr_scheduler的用法"><script integrity="sha256-DO4ugzEwhTW1Id1UIWn0gUJWaebCYOypeTit6LW4QB4=">let theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light";theme==="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-posts kind-page" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid bg-secondary wrapper"><nav class="navbar navbar-expand-xl top-navbar shadow" id=top-navbar><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button>
<i data-feather=sidebar></i>
</button>
<a class=navbar-brand href=/><img src=/images/main-logo_hu_715d6024c143d0ec.png id=logo alt=Logo>
</a><button class="navbar-toggler navbar-light" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class=nav-item><a class=nav-link href=/#skills>Skills</a></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li></ul></div></div><img src=/images/main-logo_hu_715d6024c143d0ec.png class=d-none id=main-logo alt=Logo>
<img src=/images/inverted-logo_hu_a23dc4244bee30eb.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts/ data-filter=all>Posts</a></li><div class=subtree><li><a class="active list-link" href=/posts/blogs/ title=Blogs>Blogs</a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ms-auto align-self-lg-center"><img class=rounded-circle src=/images/avatar1_hu_14556e3998f22ee9.jpg alt="Author Image"><h5 class=author-name>Xuling Chang</h5><p class=text-muted>Monday, January 1, 1</p></div><div class=title><h1>PyTorch中的lr_scheduler的用法</h1></div><div class=post-content id=post-content><p>几种常见的LR_Scheduler:</p><ul><li><a href=https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR target=_blank rel=noopener>StepLR</a></li><li><a href=https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR target=_blank rel=noopener>MultiStepLR</a></li><li><a href=https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR target=_blank rel=noopener>ExponentialLR</a></li></ul><p>对于一个基本的训练流程，LR_Scheduler可能不是必须的。但是对于一个完整的训练流程，LR_Scheduler就是必须存在的。LR_Scheduler跟在Optimizer之后，利用对Optim变量的跟踪，在Optim执行Update后，检查lr是否满足预设条件并对学习率learning_rate进行更新。</p><p>以StepLR为例，StepLR每隔N个epoch改变<code>lr</code>学习率为<code>lr=lr*gamma</code>。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Python data-lang=Python><span style=display:flex><span><span style=color:#f92672>import</span> torch.optim.lr_scheduler <span style=color:#66d9ef>as</span> lr_scheduler
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> SGD(model, <span style=color:#ae81ff>0.1</span>)
</span></span><span style=display:flex><span>scheduler <span style=color:#f92672>=</span> lr_scheduler<span style=color:#f92672>.</span>StepLR(optimizer, step_size<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, gamma<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>20</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> input, target <span style=color:#f92672>in</span> dataset:
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> model(input)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> loss_fn(output, target)
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>    scheduler<span style=color:#f92672>.</span>step()
</span></span></code></pre></div></div><div class="row ps-3 pe-3"><div class="col-md-6 share-buttons"></div></div><hr><div class="row next-prev-navigator"></div><hr></div></div></div><a id=scroll-to-top class=btn type=button data-bs-toggle=tooltip data-bs-placement=left title="Scroll to top"><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center ps-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://bigbookplus.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://bigbookplus.github.io/#skills>Skills</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:xuling.chang@live.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>xuling.chang@live.com</span></a></li></ul></div><div class="col-md-4 col-sm-12"><p>Stay up to date with email notification</p><form method=post action=https://blogtrottr.com><div class=form-group><input type=email class=form-control name=btr_email placeholder="Enter email"><br><input type=hidden name=btr_url value=https://bigbookplus.github.io//index.xml>
<input type=hidden name=schedule_type value=1>
<small id=emailHelp class="form-text text-muted">By entering your email address, you agree to receive the newsletter of this website.</small>
<button type=submit class="btn btn-info"> Submit</button></div></form></div></div></div><hr><div class=container><div class="row text-start"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu_b3360284c55cf72d.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2025 Copyright.</div><div class="col-md-4 text-end"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.0748c49f8dba141977308c83638a1587e4ad98a2ffeef8cdd20e5d57dcf95dbc.js integrity="sha256-B0jEn426FBl3MIyDY4oVh+StmKL/7vjN0g5dV9z5Xbw=" defer></script></body></html>